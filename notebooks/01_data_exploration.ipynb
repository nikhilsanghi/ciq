{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for E-commerce LLM Training\n",
    "\n",
    "This notebook explores the datasets used for training our e-commerce LLM system:\n",
    "- **ECInstruct**: Multi-task e-commerce instruction dataset\n",
    "- **Alpaca**: General instruction-following data for preventing catastrophic forgetting\n",
    "\n",
    "We'll analyze:\n",
    "1. Task distribution across classification, extraction, and Q&A\n",
    "2. Category distributions\n",
    "3. Sequence lengths for optimal `max_seq_length` selection\n",
    "4. Example prompts for each task type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install datasets transformers pandas matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load ECInstruct Dataset\n",
    "\n",
    "ECInstruct contains 116K multi-task e-commerce examples covering:\n",
    "- Product classification\n",
    "- Attribute extraction\n",
    "- Question answering\n",
    "- And more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECInstruct dataset\n",
    "print(\"Loading ECInstruct dataset...\")\n",
    "ecinstruct = load_dataset(\"NingLab/ECInstruct\", split=\"train\")\n",
    "\n",
    "print(f\"\\nDataset size: {len(ecinstruct):,} examples\")\n",
    "print(f\"Features: {ecinstruct.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample examples\n",
    "print(\"Sample Examples from ECInstruct:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(3):\n",
    "    example = ecinstruct[i]\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    for key, value in example.items():\n",
    "        # Truncate long values for display\n",
    "        display_value = str(value)[:500] + \"...\" if len(str(value)) > 500 else str(value)\n",
    "        print(f\"{key}: {display_value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Task Distribution\n",
    "\n",
    "Our e-commerce LLM handles three primary tasks:\n",
    "- **[CLASSIFY]**: Hierarchical product categorization\n",
    "- **[EXTRACT]**: Attribute-value extraction as JSON\n",
    "- **[QA]**: Product question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_task(instruction):\n",
    "    \"\"\"Categorize an instruction into task types based on keywords.\"\"\"\n",
    "    instruction_lower = instruction.lower()\n",
    "    \n",
    "    # Classification keywords\n",
    "    if any(kw in instruction_lower for kw in ['classify', 'category', 'categorize', 'product type']):\n",
    "        return 'Classification'\n",
    "    \n",
    "    # Extraction keywords\n",
    "    if any(kw in instruction_lower for kw in ['extract', 'attribute', 'specification', 'feature']):\n",
    "        return 'Extraction'\n",
    "    \n",
    "    # Q&A keywords\n",
    "    if any(kw in instruction_lower for kw in ['question', 'answer', 'what', 'how', 'why', 'does', 'is it']):\n",
    "        return 'Q&A'\n",
    "    \n",
    "    # Other e-commerce tasks\n",
    "    if any(kw in instruction_lower for kw in ['review', 'sentiment', 'rating']):\n",
    "        return 'Sentiment'\n",
    "    \n",
    "    if any(kw in instruction_lower for kw in ['similar', 'recommend', 'substitute']):\n",
    "        return 'Recommendation'\n",
    "    \n",
    "    return 'Other'\n",
    "\n",
    "# Analyze task distribution\n",
    "print(\"Analyzing task distribution...\")\n",
    "task_counts = Counter()\n",
    "\n",
    "for example in tqdm(ecinstruct, desc=\"Categorizing tasks\"):\n",
    "    instruction = example.get('instruction', '') or example.get('input', '')\n",
    "    task = categorize_task(instruction)\n",
    "    task_counts[task] += 1\n",
    "\n",
    "print(\"\\nTask Distribution:\")\n",
    "for task, count in task_counts.most_common():\n",
    "    percentage = count / len(ecinstruct) * 100\n",
    "    print(f\"  {task}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize task distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Pie chart\n",
    "tasks = list(task_counts.keys())\n",
    "counts = list(task_counts.values())\n",
    "\n",
    "colors = sns.color_palette('husl', len(tasks))\n",
    "axes[0].pie(counts, labels=tasks, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[0].set_title('Task Distribution in ECInstruct', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "df_tasks = pd.DataFrame({'Task': tasks, 'Count': counts})\n",
    "df_tasks = df_tasks.sort_values('Count', ascending=True)\n",
    "\n",
    "bars = axes[1].barh(df_tasks['Task'], df_tasks['Count'], color=colors)\n",
    "axes[1].set_xlabel('Number of Examples')\n",
    "axes[1].set_title('Task Distribution (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, df_tasks['Count']):\n",
    "    axes[1].text(count + 100, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{count:,}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Example Prompts for Each Task Type\n",
    "\n",
    "Let's examine specific examples of each task type to understand the prompt format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_examples_by_task(dataset, task_type, n=2):\n",
    "    \"\"\"Find n examples of a specific task type.\"\"\"\n",
    "    examples = []\n",
    "    for example in dataset:\n",
    "        instruction = example.get('instruction', '') or example.get('input', '')\n",
    "        if categorize_task(instruction) == task_type:\n",
    "            examples.append(example)\n",
    "            if len(examples) >= n:\n",
    "                break\n",
    "    return examples\n",
    "\n",
    "def display_example(example, task_type):\n",
    "    \"\"\"Display a formatted example.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TASK TYPE: {task_type}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    instruction = example.get('instruction', 'N/A')\n",
    "    input_text = example.get('input', 'N/A')\n",
    "    output = example.get('output', 'N/A')\n",
    "    \n",
    "    print(f\"\\n[INSTRUCTION]\\n{instruction[:1000]}\")\n",
    "    if input_text and input_text != 'N/A':\n",
    "        print(f\"\\n[INPUT]\\n{input_text[:1000]}\")\n",
    "    print(f\"\\n[OUTPUT]\\n{output[:1000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for Classification task\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# CLASSIFICATION EXAMPLES\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "classification_examples = find_examples_by_task(ecinstruct, 'Classification', n=2)\n",
    "for ex in classification_examples:\n",
    "    display_example(ex, 'Classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for Extraction task\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EXTRACTION EXAMPLES\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "extraction_examples = find_examples_by_task(ecinstruct, 'Extraction', n=2)\n",
    "for ex in extraction_examples:\n",
    "    display_example(ex, 'Extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for Q&A task\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# QUESTION & ANSWERING EXAMPLES\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "qa_examples = find_examples_by_task(ecinstruct, 'Q&A', n=2)\n",
    "for ex in qa_examples:\n",
    "    display_example(ex, 'Q&A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Sequence Lengths\n",
    "\n",
    "Understanding sequence lengths is critical for:\n",
    "- Setting `max_seq_length` during training\n",
    "- Estimating VRAM requirements\n",
    "- Avoiding truncation of important content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for sequence length analysis\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Vocabulary size: {tokenizer.vocab_size:,}\")\n",
    "print(f\"Model max length: {tokenizer.model_max_length:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(example):\n",
    "    \"\"\"Format an example into a training prompt.\"\"\"\n",
    "    instruction = example.get('instruction', '')\n",
    "    input_text = example.get('input', '')\n",
    "    output = example.get('output', '')\n",
    "    \n",
    "    # Combine instruction and input\n",
    "    if input_text:\n",
    "        full_prompt = f\"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_text}\\n\\n### Response:\\n{output}\"\n",
    "    else:\n",
    "        full_prompt = f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{output}\"\n",
    "    \n",
    "    return full_prompt\n",
    "\n",
    "# Calculate sequence lengths for a sample\n",
    "print(\"Calculating sequence lengths (sampling 10,000 examples)...\")\n",
    "\n",
    "sample_size = min(10000, len(ecinstruct))\n",
    "sample_indices = list(range(sample_size))\n",
    "\n",
    "sequence_lengths = []\n",
    "input_lengths = []\n",
    "output_lengths = []\n",
    "\n",
    "for i in tqdm(sample_indices, desc=\"Tokenizing\"):\n",
    "    example = ecinstruct[i]\n",
    "    \n",
    "    # Full prompt length\n",
    "    full_prompt = format_prompt(example)\n",
    "    tokens = tokenizer.encode(full_prompt, add_special_tokens=True)\n",
    "    sequence_lengths.append(len(tokens))\n",
    "    \n",
    "    # Input only (instruction + input)\n",
    "    instruction = example.get('instruction', '')\n",
    "    input_text = example.get('input', '')\n",
    "    input_prompt = f\"{instruction} {input_text}\".strip()\n",
    "    input_tokens = tokenizer.encode(input_prompt, add_special_tokens=True)\n",
    "    input_lengths.append(len(input_tokens))\n",
    "    \n",
    "    # Output only\n",
    "    output = example.get('output', '')\n",
    "    output_tokens = tokenizer.encode(output, add_special_tokens=False)\n",
    "    output_lengths.append(len(output_tokens))\n",
    "\n",
    "print(f\"\\nAnalyzed {len(sequence_lengths):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence length statistics\n",
    "import numpy as np\n",
    "\n",
    "def print_stats(lengths, name):\n",
    "    \"\"\"Print statistics for a list of lengths.\"\"\"\n",
    "    arr = np.array(lengths)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Min: {arr.min():,}\")\n",
    "    print(f\"  Max: {arr.max():,}\")\n",
    "    print(f\"  Mean: {arr.mean():,.1f}\")\n",
    "    print(f\"  Median: {np.median(arr):,.1f}\")\n",
    "    print(f\"  Std: {arr.std():,.1f}\")\n",
    "    print(f\"  90th percentile: {np.percentile(arr, 90):,.0f}\")\n",
    "    print(f\"  95th percentile: {np.percentile(arr, 95):,.0f}\")\n",
    "    print(f\"  99th percentile: {np.percentile(arr, 99):,.0f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SEQUENCE LENGTH STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print_stats(sequence_lengths, \"Full Sequence (Prompt + Response)\")\n",
    "print_stats(input_lengths, \"Input Only (Instruction + Input)\")\n",
    "print_stats(output_lengths, \"Output Only (Response)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sequence length distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Full sequence length distribution\n",
    "axes[0, 0].hist(sequence_lengths, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(x=2048, color='red', linestyle='--', linewidth=2, label='2048 tokens')\n",
    "axes[0, 0].axvline(x=4096, color='orange', linestyle='--', linewidth=2, label='4096 tokens')\n",
    "axes[0, 0].set_xlabel('Sequence Length (tokens)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Full Sequence Length Distribution', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Input length distribution\n",
    "axes[0, 1].hist(input_lengths, bins=50, color='forestgreen', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(x=1024, color='red', linestyle='--', linewidth=2, label='1024 tokens')\n",
    "axes[0, 1].set_xlabel('Input Length (tokens)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Input Length Distribution', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Output length distribution\n",
    "axes[1, 0].hist(output_lengths, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=512, color='red', linestyle='--', linewidth=2, label='512 tokens')\n",
    "axes[1, 0].set_xlabel('Output Length (tokens)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Output Length Distribution', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Cumulative distribution for max_seq_length selection\n",
    "sorted_lengths = np.sort(sequence_lengths)\n",
    "cumulative = np.arange(1, len(sorted_lengths) + 1) / len(sorted_lengths)\n",
    "\n",
    "axes[1, 1].plot(sorted_lengths, cumulative, color='purple', linewidth=2)\n",
    "axes[1, 1].axhline(y=0.95, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[1, 1].axhline(y=0.99, color='gray', linestyle=':', alpha=0.7)\n",
    "axes[1, 1].axvline(x=2048, color='red', linestyle='--', linewidth=2, label='2048 tokens')\n",
    "axes[1, 1].axvline(x=4096, color='orange', linestyle='--', linewidth=2, label='4096 tokens')\n",
    "axes[1, 1].set_xlabel('Sequence Length (tokens)')\n",
    "axes[1, 1].set_ylabel('Cumulative Proportion')\n",
    "axes[1, 1].set_title('Cumulative Distribution (for max_seq_length selection)', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_xlim(0, 6000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sequence_lengths.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendation for max_seq_length\n",
    "percentiles = [90, 95, 99]\n",
    "max_lengths = [2048, 3072, 4096]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MAX_SEQ_LENGTH RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for max_len in max_lengths:\n",
    "    coverage = sum(1 for l in sequence_lengths if l <= max_len) / len(sequence_lengths) * 100\n",
    "    print(f\"\\nmax_seq_length = {max_len}:\")\n",
    "    print(f\"  Coverage: {coverage:.1f}% of examples\")\n",
    "    print(f\"  Truncated: {100-coverage:.1f}% of examples\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"RECOMMENDATION: Use max_seq_length=4096 for complete coverage\")\n",
    "print(\"              or max_seq_length=2048 for faster training with ~5% truncation\")\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Preview Alpaca Dataset\n",
    "\n",
    "We mix ~10% general instruction data (Alpaca) to prevent catastrophic forgetting during fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Alpaca dataset\n",
    "print(\"Loading Alpaca dataset...\")\n",
    "alpaca = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n",
    "\n",
    "print(f\"\\nAlpaca dataset size: {len(alpaca):,} examples\")\n",
    "print(f\"Features: {alpaca.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample Alpaca examples\n",
    "print(\"\\nSample Alpaca Examples:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(3):\n",
    "    example = alpaca[i]\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Instruction: {example['instruction'][:200]}...\" if len(example['instruction']) > 200 else f\"Instruction: {example['instruction']}\")\n",
    "    print(f\"Input: {example['input'][:200]}...\" if len(str(example['input'])) > 200 else f\"Input: {example['input']}\")\n",
    "    print(f\"Output: {example['output'][:300]}...\" if len(example['output']) > 300 else f\"Output: {example['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mixing ratio\n",
    "ecommerce_size = len(ecinstruct)\n",
    "alpaca_size = len(alpaca)\n",
    "\n",
    "# We want 10% general data\n",
    "target_ratio = 0.10\n",
    "alpaca_samples_needed = int(ecommerce_size * target_ratio / (1 - target_ratio))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET MIXING STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nECInstruct examples: {ecommerce_size:,}\")\n",
    "print(f\"Alpaca examples available: {alpaca_size:,}\")\n",
    "print(f\"\\nFor 10% general data mixing:\")\n",
    "print(f\"  Alpaca samples needed: {alpaca_samples_needed:,}\")\n",
    "print(f\"  Total training examples: {ecommerce_size + alpaca_samples_needed:,}\")\n",
    "print(f\"  E-commerce ratio: {ecommerce_size / (ecommerce_size + alpaca_samples_needed) * 100:.1f}%\")\n",
    "print(f\"  General ratio: {alpaca_samples_needed / (ecommerce_size + alpaca_samples_needed) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Alpaca task types\n",
    "alpaca_tasks = []\n",
    "for example in tqdm(alpaca, desc=\"Categorizing Alpaca tasks\"):\n",
    "    instruction = example['instruction'].lower()\n",
    "    \n",
    "    if any(kw in instruction for kw in ['write', 'compose', 'create', 'generate']):\n",
    "        alpaca_tasks.append('Writing')\n",
    "    elif any(kw in instruction for kw in ['explain', 'describe', 'what is', 'define']):\n",
    "        alpaca_tasks.append('Explanation')\n",
    "    elif any(kw in instruction for kw in ['translate', 'convert']):\n",
    "        alpaca_tasks.append('Translation')\n",
    "    elif any(kw in instruction for kw in ['summarize', 'summary']):\n",
    "        alpaca_tasks.append('Summarization')\n",
    "    elif any(kw in instruction for kw in ['code', 'program', 'function', 'script']):\n",
    "        alpaca_tasks.append('Coding')\n",
    "    elif any(kw in instruction for kw in ['math', 'calculate', 'solve']):\n",
    "        alpaca_tasks.append('Math')\n",
    "    else:\n",
    "        alpaca_tasks.append('Other')\n",
    "\n",
    "alpaca_task_counts = Counter(alpaca_tasks)\n",
    "\n",
    "print(\"\\nAlpaca Task Distribution:\")\n",
    "for task, count in alpaca_task_counts.most_common():\n",
    "    print(f\"  {task}: {count:,} ({count/len(alpaca)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Task Distribution**: ECInstruct provides good coverage of classification, extraction, and Q&A tasks\n",
    "\n",
    "2. **Sequence Lengths**: \n",
    "   - Most examples fit within 2048 tokens\n",
    "   - Recommend `max_seq_length=4096` for full coverage\n",
    "   - Or `max_seq_length=2048` for faster training with minimal truncation\n",
    "\n",
    "3. **Data Mixing**:\n",
    "   - Mix ~10% Alpaca data to prevent catastrophic forgetting\n",
    "   - This maintains general instruction-following capabilities\n",
    "\n",
    "### Next Steps:\n",
    "1. Proceed to `02_training_demo.ipynb` for QLoRA fine-tuning\n",
    "2. Configure training with the recommended `max_seq_length`\n",
    "3. Implement task-specific prompt formatting with [CLASSIFY], [EXTRACT], [QA] prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results for training notebook\n",
    "analysis_results = {\n",
    "    'ecinstruct_size': len(ecinstruct),\n",
    "    'alpaca_size': len(alpaca),\n",
    "    'recommended_max_seq_length': 4096,\n",
    "    'sequence_length_95_percentile': int(np.percentile(sequence_lengths, 95)),\n",
    "    'sequence_length_99_percentile': int(np.percentile(sequence_lengths, 99)),\n",
    "    'task_distribution': dict(task_counts),\n",
    "    'alpaca_mix_ratio': 0.10\n",
    "}\n",
    "\n",
    "with open('data_exploration_results.json', 'w') as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(\"Analysis results saved to data_exploration_results.json\")\n",
    "print(json.dumps(analysis_results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
